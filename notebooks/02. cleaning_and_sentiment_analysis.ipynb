{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load tweets from mongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client.tweet_db\n",
    "col = db.tweet_collection_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_id', 'created_at', 'id', 'id_str', 'full_text', 'truncated', 'display_text_range', 'entities', 'metadata', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'retweeted_status', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'lang'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.find_one().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_tweets_from_mongo_db(db, col):\n",
    "    '''\n",
    "    load tweets from mongo_db\n",
    "    removes all retweets\n",
    "    \n",
    "    input: \"db\" (str) database name\n",
    "    input: \"col\" (str) collection name\n",
    "    \n",
    "    returns a dictionary of tweets and twitter data\n",
    "    '''\n",
    "    \n",
    "    all_tweets = defaultdict(list)\n",
    "    for tweet in col.find({\"full_text\": {\"$exists\": True}}):\n",
    "        if not tweet['retweeted'] and 'RT @' not in tweet['full_text'] and 'Retweeted' not in tweet['full_text']:\n",
    "            all_tweets['tweet'].append(tweet['full_text'])\n",
    "            all_tweets['date'].append(tweet['created_at'])\n",
    "            all_tweets['handle'].append(tweet['user']['screen_name'])\n",
    "            all_tweets['language'].append(tweet['lang'])\n",
    "            all_tweets['id'].append(tweet['_id'])\n",
    "    return all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_dict = load_tweets_from_mongo_db(db = db, col = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198748, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tweets_dict)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop non-English tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = df1['language'] != 'en'\n",
    "df1 = df1.drop(df[mask].index, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186334, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove hypertext links and newlines from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = df1['tweet'].tolist()\n",
    "remove = re.compile(r\"http\\S+|\\n|\")\n",
    "cleaned_tweets = []\n",
    "for tweet in tweets:\n",
    "    tweet = remove.sub('', tweet).strip()\n",
    "    cleaned_tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1['tweet'] = cleaned_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up the data by removing emojis, punctuation, twitter handles. This will help us peform sentiment analysis. Also I will see if there are any duplicate tweets in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ../python_files/cleaning_helper.py # python module for cleaning tweets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_clean = []\n",
    "tuples = []\n",
    "tweets = df1['tweet'].tolist()\n",
    "translator = str.maketrans('', '', remove_punctuaton) # punctuation remover\n",
    "for tweet in tweets:\n",
    "    for char in tweet:\n",
    "    \n",
    "        tweet = emojis.sub('', tweet)\n",
    "    \n",
    "    list_form = tweet.split() # turns the tweet into a list\n",
    "    \n",
    "    to_process = [x for x in list_form if not x.startswith(\"@\")] # removes twitter handles\n",
    "    \n",
    "    string_form = \" \".join(to_process) # back into a string\n",
    "    \n",
    "    set_form = set(string_form.translate(translator).strip().lower().split())\n",
    "    \n",
    "    tweets_clean.append(string_form.translate(translator).strip().lower())\n",
    "    \n",
    "    tuples.append(tuple(set_form)) # need to make it a tuple so it's hashable!\n",
    "\n",
    "df1['tuples'] = tuples\n",
    "df1['tweets_clean'] = tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186334, 7)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62689, 7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.drop_duplicates(subset='tuples', keep=\"first\") \n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### There were many duplicate tweets. This was because the same tweets were pulled multiple times or because some people were tweeting the exact same tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform sentiment analysis\n",
    "#### VADER is optimized for sentiment analysis in social media.\n",
    "#### It understands slang, emoticons, and capitilization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62689, 15)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = []\n",
    "negative = []\n",
    "neutral = []\n",
    "compound = []\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "tweets = df2['tweets_clean'].tolist()\n",
    "for tweet in tweets:\n",
    "    ss = sid.polarity_scores(tweet)\n",
    "    positive.append(ss['pos'])\n",
    "    negative.append(ss['neg'])\n",
    "    neutral.append(ss['neu'])\n",
    "    compound.append(ss['compound'])\n",
    "\n",
    "df2['positive'] = positive\n",
    "df2['negative'] = negative\n",
    "df2['neutral'] = neutral\n",
    "df2['compound'] = compound\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create columns for each airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handles = ['@united', '@Delta', '@SouthwestAir', '@AmericanAir']\n",
    "airlines = ['United', 'Delta', 'Southwest', 'American']\n",
    "\n",
    "for handle, airline in zip(handles, airlines):\n",
    "    mask = df2['tweet'].str.lower().str.contains(handle.lower())\n",
    "    df2.loc[mask, airline] = 1\n",
    "    df2.loc[~mask, airline] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>compound</th>\n",
       "      <th>United</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Southwest</th>\n",
       "      <th>American</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62689.000000</td>\n",
       "      <td>62689.000000</td>\n",
       "      <td>62689.000000</td>\n",
       "      <td>62689.000000</td>\n",
       "      <td>62689.000000</td>\n",
       "      <td>62689.000000</td>\n",
       "      <td>62689.000000</td>\n",
       "      <td>62689.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.139925</td>\n",
       "      <td>0.088818</td>\n",
       "      <td>0.771207</td>\n",
       "      <td>0.084594</td>\n",
       "      <td>0.195616</td>\n",
       "      <td>0.287834</td>\n",
       "      <td>0.230902</td>\n",
       "      <td>0.310852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.176979</td>\n",
       "      <td>0.134389</td>\n",
       "      <td>0.193620</td>\n",
       "      <td>0.445081</td>\n",
       "      <td>0.396678</td>\n",
       "      <td>0.452757</td>\n",
       "      <td>0.421413</td>\n",
       "      <td>0.462846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.970200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>-0.226300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.231000</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.440400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           positive      negative       neutral      compound        United  \\\n",
       "count  62689.000000  62689.000000  62689.000000  62689.000000  62689.000000   \n",
       "mean       0.139925      0.088818      0.771207      0.084594      0.195616   \n",
       "std        0.176979      0.134389      0.193620      0.445081      0.396678   \n",
       "min        0.000000      0.000000      0.000000     -0.970200      0.000000   \n",
       "25%        0.000000      0.000000      0.653000     -0.226300      0.000000   \n",
       "50%        0.088000      0.000000      0.788000      0.000000      0.000000   \n",
       "75%        0.231000      0.152000      0.940000      0.440400      0.000000   \n",
       "max        1.000000      1.000000      1.000000      0.987400      1.000000   \n",
       "\n",
       "              Delta     Southwest      American  \n",
       "count  62689.000000  62689.000000  62689.000000  \n",
       "mean       0.287834      0.230902      0.310852  \n",
       "std        0.452757      0.421413      0.462846  \n",
       "min        0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.000000  \n",
       "50%        0.000000      0.000000      0.000000  \n",
       "75%        1.000000      0.000000      1.000000  \n",
       "max        1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are interested in the \"compound\" column. It is a measure of overall sentiment for a given tweet. Its range is from -1 for negative tweets, to +1 for positive tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([22502], dtype='int64')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[df2['compound'] == df2['compound'].max()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([53809], dtype='int64')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[df2['compound'] == df2['compound'].min()].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highest and lowest sentiment scoring tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love love love, love love love @Delta! Thanks Stephanie for awesome customer service as usual!! #RonR'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['tweet'][22502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@ChristiChat @anntensity @NAACP @AmericanAir Racist! Saying that Racist NAACP is Racist is AA is Racist! Yes that line makes as much sense as any words that come from NAACP. They are irrelevant now. Because everyone who disagrees with them is racist, nothing for them to prove. #maga #covfefe'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['tweet'][52782]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.to_pickle('../pickle_files/df1.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
