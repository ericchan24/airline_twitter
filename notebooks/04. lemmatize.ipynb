{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ../python_files/cleaning_helper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../pickle_files/df2.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61711, 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatize the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for i in range(len(df)):\n",
    "    text = df.loc[i,'tweets_clean1']\n",
    "    tokens = nlp(text)\n",
    "    words = []\n",
    "    for token in tokens:\n",
    "        if token.is_space:\n",
    "            continue\n",
    "        elif token.text in remove_punctuaton: # from my cleaning module\n",
    "            continue\n",
    "        elif token.is_punct:\n",
    "            continue\n",
    "        elif token.is_stop:\n",
    "            continue\n",
    "        elif token.is_digit:\n",
    "            continue\n",
    "        elif len(token) <= 1:\n",
    "            continue\n",
    "        else:\n",
    "            words.append(token.lemma_)\n",
    "            \n",
    "    tweet = ' '.join(words)\n",
    "    tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61711"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nah tweet'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = np.random.choice(len(tweets))\n",
    "tweets[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['lemmatized_tweets'] = tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>handle</th>\n",
       "      <th>id</th>\n",
       "      <th>language</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tuples</th>\n",
       "      <th>tweets_clean</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>compound</th>\n",
       "      <th>United</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Southwest</th>\n",
       "      <th>American</th>\n",
       "      <th>tweets_clean1</th>\n",
       "      <th>time</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>Number of hashtags</th>\n",
       "      <th>lemmatized_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>eirbearrr</td>\n",
       "      <td>59fd32ff291ebbf619c97774</td>\n",
       "      <td>en</td>\n",
       "      <td>@united And the plane is sitting here they won...</td>\n",
       "      <td>(sitting, us, theres, is, and, they, here, let...</td>\n",
       "      <td>and the plane is sitting here they wont let ...</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>plane sitting will not let us there is one hel...</td>\n",
       "      <td>03:23:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>plane sitting let help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>arlohemphill</td>\n",
       "      <td>59fd32ff291ebbf619c97775</td>\n",
       "      <td>en</td>\n",
       "      <td>@united Sure, DMing now</td>\n",
       "      <td>(now, sure, dming)</td>\n",
       "      <td>sure dming now</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sure direct messaging</td>\n",
       "      <td>03:23:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>sure direct messaging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>JDR1024</td>\n",
       "      <td>59fd32ff291ebbf619c97776</td>\n",
       "      <td>en</td>\n",
       "      <td>@united United should show the elite status of...</td>\n",
       "      <td>(should, united, status, passengers, show, of,...</td>\n",
       "      <td>united should show the elite status of passe...</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>united show elite status passengers upgrade list</td>\n",
       "      <td>03:22:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>united elite status passenger upgrade list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>loooorenanicole</td>\n",
       "      <td>59fd32ff291ebbf619c97777</td>\n",
       "      <td>en</td>\n",
       "      <td>@united I'm SO DISAPPOINTED in your cust suppo...</td>\n",
       "      <td>(so, in, your, shame, you, disappointed, suppo...</td>\n",
       "      <td>im so disappointed in your cust support sham...</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.432</td>\n",
       "      <td>-0.5849</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i am disappointed customer support shame</td>\n",
       "      <td>03:22:11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>disappointed customer support shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>loooorenanicole</td>\n",
       "      <td>59fd32ff291ebbf619c97779</td>\n",
       "      <td>en</td>\n",
       "      <td>@united INCREDIBLY frustrated w/cust support, ...</td>\n",
       "      <td>(losing, due, time, incredibly, united, perks,...</td>\n",
       "      <td>incredibly frustrated wcust support im losin...</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.537</td>\n",
       "      <td>-0.1354</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>incredibly frustrated with customer support i ...</td>\n",
       "      <td>03:20:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>incredibly frustrated customer support lose tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date           handle                        id language  \\\n",
       "0 2017-11-04        eirbearrr  59fd32ff291ebbf619c97774       en   \n",
       "1 2017-11-04     arlohemphill  59fd32ff291ebbf619c97775       en   \n",
       "2 2017-11-04          JDR1024  59fd32ff291ebbf619c97776       en   \n",
       "3 2017-11-04  loooorenanicole  59fd32ff291ebbf619c97777       en   \n",
       "4 2017-11-04  loooorenanicole  59fd32ff291ebbf619c97779       en   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  @united And the plane is sitting here they won...   \n",
       "1                            @united Sure, DMing now   \n",
       "2  @united United should show the elite status of...   \n",
       "3  @united I'm SO DISAPPOINTED in your cust suppo...   \n",
       "4  @united INCREDIBLY frustrated w/cust support, ...   \n",
       "\n",
       "                                              tuples  \\\n",
       "0  (sitting, us, theres, is, and, they, here, let...   \n",
       "1                                 (now, sure, dming)   \n",
       "2  (should, united, status, passengers, show, of,...   \n",
       "3  (so, in, your, shame, you, disappointed, suppo...   \n",
       "4  (losing, due, time, incredibly, united, perks,...   \n",
       "\n",
       "                                        tweets_clean  positive  negative  \\\n",
       "0    and the plane is sitting here they wont let ...     0.123     0.100   \n",
       "1                                   sure dming now       0.535     0.000   \n",
       "2    united should show the elite status of passe...     0.203     0.000   \n",
       "3    im so disappointed in your cust support sham...     0.167     0.401   \n",
       "4    incredibly frustrated wcust support im losin...     0.221     0.242   \n",
       "\n",
       "   neutral  compound  United  Delta  Southwest  American  \\\n",
       "0    0.776    0.1280     1.0    0.0        0.0       0.0   \n",
       "1    0.465    0.3182     1.0    0.0        0.0       0.0   \n",
       "2    0.797    0.4215     1.0    0.0        0.0       0.0   \n",
       "3    0.432   -0.5849     1.0    0.0        0.0       0.0   \n",
       "4    0.537   -0.1354     1.0    0.0        1.0       0.0   \n",
       "\n",
       "                                       tweets_clean1      time hashtags  \\\n",
       "0  plane sitting will not let us there is one hel...  03:23:36      NaN   \n",
       "1                              sure direct messaging  03:23:34      NaN   \n",
       "2   united show elite status passengers upgrade list  03:22:36      NaN   \n",
       "3           i am disappointed customer support shame  03:22:11      NaN   \n",
       "4  incredibly frustrated with customer support i ...  03:20:36      NaN   \n",
       "\n",
       "   Number of hashtags                                  lemmatized_tweets  \n",
       "0                   0                             plane sitting let help  \n",
       "1                   0                              sure direct messaging  \n",
       "2                   0         united elite status passenger upgrade list  \n",
       "3                   0                disappointed customer support shame  \n",
       "4                   0  incredibly frustrated customer support lose tr...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle('../pickle_files/df3.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
